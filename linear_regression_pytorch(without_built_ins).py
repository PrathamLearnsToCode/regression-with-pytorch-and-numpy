# -*- coding: utf-8 -*-
"""linear_regression_pytorch(without built-ins).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qSdjsJzcN79GGYrshc0wuTEMnwX0tdBE
"""

import torch
import numpy as np
inputs = np.array([[73, 67, 43], 
                   [91, 88, 64], 
                   [87, 134, 58], 
                   [102, 43, 37], 
                   [69, 96, 70]], dtype='float32')
outputs = np.array([[56, 70], 
                    [81, 101], 
                    [119, 133], 
                    [22, 37], 
                    [103, 119]], dtype='float32')
inputs = torch.from_numpy(inputs)
outputs = torch.from_numpy(outputs)

w = torch.randn(2,3, requires_grad = True)
b = torch.randn(2, requires_grad = True)

def model(x):
  return x @ w.t() + b
def mse(t1, t2):
  diff = t1 - t2
  return torch.sum(diff*diff)/diff.numel()

predicted = model(inputs)
print("The predicted values are following:")
print(predicted,end = '\n')
print()
print("The actual Output is given as following:")
print(outputs)
print()
print("The mean square loss between observed and actual prediction is:")
loss = mse(predicted, outputs)
print(loss)
loss.backward()
print()
print("The derivate of loss with respect to w is:")
print(w.grad)
with torch.no_grad():
    w -= w.grad * 1e-5
    b -= b.grad * 1e-5
w.grad.zero_()
b.grad.zero_()
prediction = model(inputs)
print()
print("The predicted value after adjusting weights is:")
print(prediction)
loss = mse(prediction, outputs)
print()
print("The mean sqaure loss after adjusting the weights is:")
print(loss)

for i in range(1,120):
  predicted = model(inputs)
  loss = mse(predicted, outputs)
  loss.backward()
  with torch.no_grad():
        w -= w.grad * 1e-5
        b -= b.grad * 1e-5
        w.grad.zero_()
        b.grad.zero_()
loss = mse(predicted, outputs)
print()
print("The mean square loss after applying multiple epochs:")
print(loss)